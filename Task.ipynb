{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\seppe\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\seppe\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\seppe\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.24.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\seppe\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\seppe\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\seppe\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on X:  [[16.8 ]\n",
      " [27.  ]\n",
      " [32.26]\n",
      " [33.74]\n",
      " [26.08]\n",
      " [15.18]\n",
      " [35.8 ]\n",
      " [28.86]\n",
      " [26.44]\n",
      " [12.2 ]\n",
      " [14.7 ]\n",
      " [26.32]\n",
      " [28.9 ]\n",
      " [30.66]\n",
      " [23.84]\n",
      " [34.58]\n",
      " [28.08]\n",
      " [19.94]\n",
      " [22.36]\n",
      " [14.7 ]\n",
      " [33.74]\n",
      " [25.6 ]\n",
      " [21.42]\n",
      " [16.6 ]\n",
      " [18.52]\n",
      " [14.1 ]\n",
      " [33.18]\n",
      " [13.  ]\n",
      " [31.6 ]\n",
      " [33.44]\n",
      " [34.38]\n",
      " [27.8 ]\n",
      " [18.06]\n",
      " [33.44]\n",
      " [27.16]\n",
      " [23.38]\n",
      " [31.6 ]\n",
      " [19.46]\n",
      " [32.58]\n",
      " [19.12]\n",
      " [13.4 ]\n",
      " [23.38]\n",
      " [27.02]\n",
      " [18.3 ]\n",
      " [25.96]\n",
      " [24.98]\n",
      " [33.12]\n",
      " [23.04]\n",
      " [34.58]\n",
      " [29.1 ]\n",
      " [33.44]\n",
      " [32.96]\n",
      " [34.3 ]\n",
      " [19.58]\n",
      " [23.4 ]\n",
      " [19.04]\n",
      " [18.18]\n",
      " [35.48]\n",
      " [32.4 ]\n",
      " [31.18]\n",
      " [17.8 ]\n",
      " [14.  ]\n",
      " [15.  ]\n",
      " [17.8 ]\n",
      " [20.3 ]\n",
      " [33.4 ]\n",
      " [28.24]\n",
      " [25.  ]\n",
      " [26.34]\n",
      " [26.58]\n",
      " [14.3 ]\n",
      " [15.1 ]\n",
      " [22.36]\n",
      " [25.58]\n",
      " [16.68]\n",
      " [33.86]\n",
      " [12.2 ]\n",
      " [25.34]\n",
      " [18.82]\n",
      " [33.12]\n",
      " [27.2 ]\n",
      " [16.7 ]\n",
      " [29.86]\n",
      " [19.48]\n",
      " [16.64]\n",
      " [14.7 ]\n",
      " [16.62]\n",
      " [34.3 ]\n",
      " [18.94]\n",
      " [15.28]\n",
      " [13.2 ]\n",
      " [22.36]\n",
      " [14.84]\n",
      " [24.04]\n",
      " [33.56]\n",
      " [19.8 ]\n",
      " [18.26]\n",
      " [13.2 ]\n",
      " [25.18]\n",
      " [18.44]\n",
      " [34.24]\n",
      " [27.08]\n",
      " [13.4 ]\n",
      " [18.32]\n",
      " [26.6 ]\n",
      " [33.12]\n",
      " [20.94]\n",
      " [20.44]\n",
      " [20.3 ]\n",
      " [31.68]\n",
      " [30.88]\n",
      " [16.6 ]\n",
      " [27.26]\n",
      " [35.2 ]\n",
      " [22.9 ]\n",
      " [14.9 ]\n",
      " [20.94]\n",
      " [32.78]\n",
      " [26.72]\n",
      " [25.48]\n",
      " [23.34]\n",
      " [25.26]\n",
      " [21.26]\n",
      " [30.3 ]\n",
      " [15.5 ]\n",
      " [16.04]\n",
      " [30.14]\n",
      " [27.64]\n",
      " [29.7 ]\n",
      " [25.94]\n",
      " [26.52]\n",
      " [26.34]\n",
      " [24.98]\n",
      " [34.88]\n",
      " [17.42]\n",
      " [21.9 ]\n",
      " [29.82]\n",
      " [18.32]\n",
      " [25.3 ]\n",
      " [23.94]\n",
      " [33.12]\n",
      " [14.9 ]\n",
      " [19.18]\n",
      " [18.82]\n",
      " [30.88]\n",
      " [27.96]\n",
      " [16.8 ]\n",
      " [33.32]\n",
      " [15.  ]\n",
      " [15.08]\n",
      " [25.58]\n",
      " [13.48]\n",
      " [22.32]\n",
      " [28.48]\n",
      " [14.9 ]\n",
      " [33.98]\n",
      " [33.56]\n",
      " [22.32]\n",
      " [28.6 ]\n",
      " [23.02]\n",
      " [14.9 ]\n",
      " [27.64]\n",
      " [27.  ]\n",
      " [29.  ]\n",
      " [34.98]\n",
      " [21.42]\n",
      " [33.88]\n",
      " [26.06]\n",
      " [16.32]\n",
      " [35.4 ]\n",
      " [27.7 ]\n",
      " [15.28]\n",
      " [12.2 ]\n",
      " [20.9 ]\n",
      " [14.3 ]\n",
      " [27.78]\n",
      " [14.  ]\n",
      " [24.48]\n",
      " [32.28]\n",
      " [14.  ]\n",
      " [16.52]\n",
      " [18.72]\n",
      " [12.4 ]\n",
      " [24.1 ]\n",
      " [32.82]\n",
      " [30.16]\n",
      " [24.96]\n",
      " [16.04]\n",
      " [12.2 ]\n",
      " [35.2 ]\n",
      " [30.16]\n",
      " [19.74]\n",
      " [38.52]\n",
      " [25.48]\n",
      " [15.1 ]\n",
      " [33.68]\n",
      " [27.1 ]\n",
      " [20.  ]\n",
      " [24.16]\n",
      " [16.8 ]\n",
      " [18.88]\n",
      " [28.86]\n",
      " [24.16]\n",
      " [20.66]\n",
      " [26.04]\n",
      " [15.  ]\n",
      " [26.22]\n",
      " [18.44]\n",
      " [18.32]\n",
      " [26.72]\n",
      " [18.44]\n",
      " [29.86]\n",
      " [27.3 ]\n",
      " [18.58]\n",
      " [25.04]\n",
      " [13.48]\n",
      " [34.28]\n",
      " [14.7 ]\n",
      " [18.32]\n",
      " [15.34]\n",
      " [17.2 ]\n",
      " [27.26]\n",
      " [13.2 ]\n",
      " [14.3 ]\n",
      " [18.32]\n",
      " [18.72]\n",
      " [13.8 ]\n",
      " [14.9 ]\n",
      " [20.46]\n",
      " [25.6 ]\n",
      " [13.4 ]\n",
      " [14.8 ]\n",
      " [18.32]\n",
      " [34.3 ]\n",
      " [33.8 ]\n",
      " [35.62]\n",
      " [28.58]\n",
      " [26.36]\n",
      " [23.68]\n",
      " [13.48]\n",
      " [31.82]\n",
      " [25.3 ]\n",
      " [17.98]\n",
      " [27.26]\n",
      " [20.  ]\n",
      " [32.16]\n",
      " [28.92]\n",
      " [18.42]\n",
      " [15.8 ]\n",
      " [12.8 ]\n",
      " [28.9 ]\n",
      " [15.5 ]\n",
      " [33.46]\n",
      " [20.9 ]\n",
      " [14.  ]\n",
      " [35.48]\n",
      " [16.6 ]\n",
      " [26.72]\n",
      " [27.18]\n",
      " [32.4 ]\n",
      " [19.48]\n",
      " [18.92]\n",
      " [13.  ]\n",
      " [28.88]\n",
      " [32.44]\n",
      " [18.02]\n",
      " [22.36]\n",
      " [20.22]\n",
      " [21.82]\n",
      " [14.8 ]\n",
      " [25.18]\n",
      " [17.32]\n",
      " [25.26]\n",
      " [26.8 ]\n",
      " [18.26]\n",
      " [25.32]\n",
      " [32.78]\n",
      " [27.66]\n",
      " [24.9 ]\n",
      " [34.24]\n",
      " [27.82]\n",
      " [21.86]\n",
      " [15.3 ]\n",
      " [25.94]\n",
      " [15.5 ]\n",
      " [20.52]\n",
      " [28.6 ]\n",
      " [17.8 ]\n",
      " [34.88]\n",
      " [27.64]\n",
      " [19.74]\n",
      " [27.78]\n",
      " [27.96]\n",
      " [15.8 ]\n",
      " [22.36]\n",
      " [20.42]\n",
      " [31.82]\n",
      " [35.48]\n",
      " [19.58]\n",
      " [27.7 ]\n",
      " [27.06]\n",
      " [27.8 ]\n",
      " [32.9 ]\n",
      " [27.  ]\n",
      " [19.4 ]\n",
      " [26.36]\n",
      " [14.7 ]\n",
      " [35.36]\n",
      " [16.34]\n",
      " [17.98]\n",
      " [26.02]\n",
      " [25.28]\n",
      " [15.5 ]\n",
      " [27.98]\n",
      " [12.8 ]\n",
      " [27.26]\n",
      " [32.2 ]\n",
      " [32.12]]\n",
      "Based on Toyota Celica:  [[28.1]]\n",
      "Mean squared error: 12.910669182389938\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Fetch dataset\n",
    "auto_mpg = fetch_ucirepo(id=9)\n",
    "\n",
    "#Data (as pandas dataframes)\n",
    "X = auto_mpg.data.features\n",
    "y = auto_mpg.data.targets\n",
    "\n",
    "#Een functie om X en y te printen zodat het zichtbaar is wat er in het model zit\n",
    "def printX(X):\n",
    "    \n",
    "    print(X)\n",
    "\n",
    "def printY(y):\n",
    "    \n",
    "    print(y)\n",
    "\n",
    "\n",
    "#X moet getransformeerd worden omdat er NaN waarden inzitten. Deze NaN waarden moeten ingevuld worden, dit wordt nu gedaan door de mediaan te nemen.\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "#De eerste functie is die van Lineare regressie.\n",
    "def linear(X,y):\n",
    "\n",
    "    #Het model wordt gemaakt\n",
    "    model = LinearRegression()\n",
    "\n",
    "    #Data wordt aan het model toegevoed. Als er eerde niet de Nan waarden waren vervangen had dit een error gegeven.\n",
    "    model.fit(X, y)\n",
    "\n",
    "    #Alle X rows worden nu gegeven om op te testen.\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "\n",
    "    #Data gebruikt van https://www.auto-data.net/en/toyota-celica-t18-1.6-sti-105hp-3133 om een keer met een echt voorbeeld te testen\n",
    "    new_data = np.array([[97.7,4,105,2645.55,11,93,2]])\n",
    "    predicted_values = model.predict(new_data)\n",
    "\n",
    "\n",
    "    print(\"Based on X: \",predictions)\n",
    "    print(\"Based on Toyota Celica: \",predicted_values)\n",
    "    print(\"Mean squared error:\", mse)\n",
    "\n",
    "\n",
    "def knn(X,y):\n",
    "    #Maak training en test datasets van de data.\n",
    "    #In deze demo wordt enkel de train data gebruikt om een zo accuraat mogelijke prediction te krijgen en om de vergelijking te kunnen maken met lineare regressie.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Knn model met het aantal neighbors\n",
    "    knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "    #Data wordt aan het model toegevoed. Als er eerde niet de Nan waarden waren vervangen had dit een error gegeven.\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    #Een prediction van y (mpg) wordt gemaakt op basis van de X training data. Hier zou normaalgezien de X_test data gebruikt worden.\n",
    "    y_pred = knn.predict(X_train)\n",
    "\n",
    "    #Bekijk wat de waarde van de mean squared error is. Hierdoor krijgen we toch een idee met wat voor foutmarge we moeten rekening houden.\n",
    "    mse = mean_squared_error(y_train, y_pred)\n",
    "\n",
    "    #Ook hier weer een extra test met echte data. Het is dezelfde als bij de lineare regressie dus kan er ook hierop vergeleken worden.\n",
    "    new_data = np.array([[97.7,4,105,2645.55,11,93,2]])\n",
    "    predicted_values = knn.predict(new_data)\n",
    "    prediction = knn.predict(X_train)\n",
    "\n",
    "    \n",
    "    print(\"Based on X: \", prediction)\n",
    "    print(\"Based on Toyota Celica: \", predicted_values)\n",
    "    print(\"Mean squared error:\", mse)\n",
    "\n",
    "def poly(X,y):\n",
    "\n",
    "    degree = 2\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model to the polynomial features\n",
    "    model.fit(X_poly, y)\n",
    "\n",
    "    \n",
    "\n",
    "    new_data = np.array([[97.7, 4, 105, 2645.55, 11, 93, 2]])\n",
    "    new_data_poly = poly_features.transform(new_data)\n",
    "    predict = model.predict(new_data_poly)\n",
    "\n",
    "    y_pred = model.predict(X_poly)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "    print(y_pred)\n",
    "    print(predict)\n",
    "    print(mse)\n",
    "\n",
    "\n",
    "linear(X,y)\n",
    "knn(X,y)\n",
    "poly(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taak Machine Learning - Seppe Van Eynde\n",
    "\n",
    "\n",
    "In deze tweede taak van AI is de opdracht om 3 verschillende ML algorithmes te gebruiken om uitkomsten te voorspellen. Hiervoor ga ik voorspellingen maken over hoever mpg een auto zal hebben op basis van enkele parameters.\n",
    "Een van de drie algorithmes diende uit de geziene leerstof te komen. Ik heb dan ook gekozen voor linear regression aangezien ik graag met regressie zou werken voor deze taak en omdat het een relatief makkelijk algorithme is. Voor de andere twee heb ik gekozen voor K nearest neighbor en voor polynominal regression. \n",
    "\n",
    "KNN zal kijken naar het gemiddelde van de nabij gelegen waarden (neigbors) en zal dit dan toewijzen aan de prediction. In het geval van mijn dataset zal er dan gekeken worden naar 7 waarden namelijk: displacement, cylinder, horsepower, weight, acceleration, model year en origin. Als het algorithme zijn ding heeft gedaan zal de output een nummer zijn van hoeveel mpg een bepaalde auto zal hebben.\n",
    "\n",
    "Polynominal regression laat toe om iets complexere modellen te gebruiken op het gebied van de relatie tussen de input features en de target variables. \n",
    "\n",
    "Voor zowel KNN als Polynominal Regression heb ik gebruik gemaakt van ChatGPT. Het heeft me de basis van beide concepten uitgelegd en getoond hoe de code te werk gaat waarna ik dat als voorbeeld gebruikt heb voor mijn eigen code.\n",
    "\n",
    "Het is duidelijk dat de drie algorithmen een verschil hebben tegenover elkaar en de originele data.\n",
    "\n",
    "Bekijk zeker de Streamlit app voor een iets overzichtelijker resultaat! https://regression-seppeve.streamlit.app/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
